{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from skimage.data import astronaut\n",
    "from skimage.segmentation import slic\n",
    "from scipy.spatial import Delaunay\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage.color import label2rgb\n",
    "from skimage.transform import resize\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Train Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting dataset and k\n",
    "dataset_name = 'BUSI-with-GT'  # 'BUSI-with-GT' or  'BUSBRA' \n",
    "k = 6  # '2' '4' '6' '8'\n",
    "\n",
    "\n",
    "patch_dir  = 'Dataset/' + dataset_name + '/data-edge/k' + str(k) + '/'\n",
    "folder = 'train'\n",
    "\n",
    "# Usage\n",
    "folder_path = patch_dir + folder + '/' + 'patch-image/All/' # replace with your folder path\n",
    "model_path = patch_dir + 'Vgg_model.h5'\n",
    "\n",
    "attrs = []\n",
    "\n",
    "def extract_features(model, img_array):\n",
    "    # img = image.load_img(image_path, target_size=(image_shape[0], image_shape[1]))\n",
    "    # img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "    features = model.predict(img_array, verbose=0)\n",
    "    return features.flatten()\n",
    "\n",
    "\n",
    "model_vgg = tf.keras.models.load_model(model_path)\n",
    "\n",
    "model = Model(model_vgg.input, model_vgg.layers[-2].output)\n",
    "\n",
    "image_files = sorted(os.listdir(folder_path), key=lambda x: int(x.split('.')[0]))\n",
    "images = []\n",
    "for image_file in image_files:\n",
    "    image_path = os.path.join(folder_path, image_file)\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    feature_vector = extract_features(model, image)\n",
    "    feature_vector = feature_vector.reshape(1, -1)\n",
    "    feature_vector = feature_vector.tolist()\n",
    "    feature_vector = feature_vector[0]\n",
    "\n",
    "    attrs.append(feature_vector)\n",
    "\n",
    "\n",
    "    print(image_file)\n",
    "\n",
    "\n",
    "df_node_attr = pd.DataFrame(data = np.array(attrs))\n",
    "print(\"shape of node-attribute dataframe: \" + str(df_node_attr.shape))\n",
    "print(\"\\n--summary of dataframe--\\n\", df_node_attr.head(50))\n",
    "\n",
    "sourcepath = patch_dir + 'raw'\n",
    "def save_dataframe_to_txt(df, filepath):\n",
    "    df.to_csv(filepath, header=None, index=None, sep=',', mode='w')\n",
    "\n",
    "save_dataframe_to_txt(df_node_attr, sourcepath + '/train_node_attributes.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Test Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting dataset and k\n",
    "dataset_name = 'BUSI-with-GT'  # 'BUSI-with-GT' or  'BUSBRA' \n",
    "k = 6  # '2' '4' '6' '8'\n",
    "\n",
    "\n",
    "patch_dir  = 'Dataset/' + dataset_name + '/data-edge/k' + str(k) + '/'\n",
    "folder = 'test'\n",
    "\n",
    "# Usage\n",
    "folder_path = patch_dir + folder + '/' + 'patch-image/All/' # replace with your folder path\n",
    "model_path = patch_dir + 'Vgg_model.h5'\n",
    "\n",
    "attrs = []\n",
    "\n",
    "def extract_features(model, img_array):\n",
    "    # img = image.load_img(image_path, target_size=(image_shape[0], image_shape[1]))\n",
    "    # img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    features = model.predict(img_array, verbose=0)\n",
    "    return features.flatten()\n",
    "\n",
    "\n",
    "\n",
    "model_vgg = tf.keras.models.load_model(model_path)\n",
    "\n",
    "model = Model(model_vgg.input, model_vgg.layers[-2].output)\n",
    "\n",
    "\n",
    "image_files = sorted(os.listdir(folder_path), key=lambda x: int(x.split('.')[0]))\n",
    "images = []\n",
    "for image_file in image_files:\n",
    "    image_path = os.path.join(folder_path, image_file)\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    feature_vector = extract_features(model, image)\n",
    "    feature_vector = feature_vector.reshape(1, -1)\n",
    "    feature_vector = feature_vector.tolist()\n",
    "    feature_vector = feature_vector[0]\n",
    "\n",
    "    attrs.append(feature_vector)\n",
    "\n",
    "\n",
    "    print(image_file)\n",
    "\n",
    "\n",
    "df_node_attr = pd.DataFrame(data = np.array(attrs))\n",
    "print(\"shape of node-attribute dataframe: \" + str(df_node_attr.shape))\n",
    "print(\"\\n--summary of dataframe--\\n\", df_node_attr.head(50))\n",
    "\n",
    "\n",
    "sourcepath = patch_dir + 'raw'\n",
    "def save_dataframe_to_txt(df, filepath):\n",
    "    df.to_csv(filepath, header=None, index=None, sep=',', mode='w')\n",
    "\n",
    "save_dataframe_to_txt(df_node_attr, sourcepath + '/test_node_attributes.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
